{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDq7W9YCEt_n",
        "outputId": "2655346f-eadc-4532-b2ab-4902c2c4852c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Accuracy: 0.41925\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.07      0.13      2386\n",
            "           1       0.40      0.93      0.56      1614\n",
            "\n",
            "    accuracy                           0.42      4000\n",
            "   macro avg       0.51      0.50      0.35      4000\n",
            "weighted avg       0.53      0.42      0.31      4000\n",
            "\n",
            "Model saved to /content/drive/MyDrive/gbm_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "# Step 1: Generate Realistic Synthetic Data\n",
        "num_samples = 20000\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def generate_realistic_heart_rate():\n",
        "    return np.random.normal(loc=75, scale=5, size=num_samples)\n",
        "\n",
        "def generate_realistic_hrv_mean():\n",
        "    return np.random.normal(loc=50, scale=15, size=num_samples)\n",
        "\n",
        "def generate_realistic_bp_systolic():\n",
        "    return np.random.normal(loc=120, scale=10, size=num_samples)\n",
        "\n",
        "def generate_realistic_bp_diastolic():\n",
        "    return np.random.normal(loc=80, scale=5, size=num_samples)\n",
        "\n",
        "def generate_target():\n",
        "    return np.random.choice([0, 1], size=num_samples, p=[0.6, 0.4])  # Increased high-risk samples to 40%\n",
        "\n",
        "avg_heart_rate = generate_realistic_heart_rate()\n",
        "hrv_mean = generate_realistic_hrv_mean()\n",
        "bp_systolic = generate_realistic_bp_systolic()\n",
        "bp_diastolic = generate_realistic_bp_diastolic()\n",
        "target = generate_target()\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'average_heart_rate': avg_heart_rate,\n",
        "    'hrv_mean': hrv_mean,\n",
        "    'blood_pressure_systolic': bp_systolic,\n",
        "    'blood_pressure_diastolic': bp_diastolic,\n",
        "    'target': target\n",
        "})\n",
        "\n",
        "# Save synthetic data to CSV (optional)\n",
        "data.to_csv('synthetic_gbm_data.csv', index=False)\n",
        "\n",
        "# Step 2: Authenticate and Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 3: Preprocess Data\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model = XGBClassifier(scale_pos_weight=2)  # Adjusted to give more weight to high-risk samples\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_pred_adjusted = (y_pred_proba > 0.3).astype(int)  # Lowered threshold for high-risk classification\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_adjusted))\n",
        "\n",
        "# Step 5: Save the Model to Google Drive\n",
        "model_filename = '/content/drive/MyDrive/gbm_model.pkl'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzU-Yf4xjp9c",
        "outputId": "40d2bc13-d823-44eb-b9d3-186267832d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.26.2 xgboost-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the saved model\n",
        "model_filename = '/content/drive/MyDrive/project models/gbm_model.pkl'\n",
        "loaded_model = joblib.load(model_filename)\n",
        "print(f\"Model loaded from {model_filename}\")\n",
        "\n",
        "# Generate new data for inference (you can replace this with real data)\n",
        "num_samples = 5\n",
        "\n",
        "def generate_inference_data():\n",
        "    return pd.DataFrame({\n",
        "        'average_heart_rate': np.random.normal(loc=75, scale=5, size=num_samples),\n",
        "        'hrv_mean': np.random.normal(loc=50, scale=15, size=num_samples),\n",
        "        'blood_pressure_systolic': np.random.normal(loc=120, scale=10, size=num_samples),\n",
        "        'blood_pressure_diastolic': np.random.normal(loc=80, scale=5, size=num_samples)\n",
        "    })\n",
        "\n",
        "new_data = generate_inference_data()\n",
        "\n",
        "# Make predictions\n",
        "predictions = loaded_model.predict(new_data)\n",
        "probabilities = loaded_model.predict_proba(new_data)[:, 1]\n",
        "\n",
        "# Add predictions to the DataFrame\n",
        "new_data['predicted_risk'] = predictions\n",
        "new_data['risk_probability'] = probabilities\n",
        "\n",
        "# Print results\n",
        "print(\"\\nInference Results:\")\n",
        "print(new_data)\n",
        "print(\"\\nPredicted Risk: 0 = Low Risk, 1 = High Risk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuxHbN2o0D18",
        "outputId": "a738314e-7fd7-49f5-80e3-ef5cd00097ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model loaded from /content/drive/MyDrive/project models/gbm_model.pkl\n",
            "\n",
            "Inference Results:\n",
            "   average_heart_rate   hrv_mean  blood_pressure_systolic  \\\n",
            "0           73.176956  34.729675               115.652572   \n",
            "1           67.670995  44.131139               118.964901   \n",
            "2           78.892273  53.551864               118.200728   \n",
            "3           74.457990  31.924377               106.539584   \n",
            "4           74.716125  47.482336               128.486420   \n",
            "\n",
            "   blood_pressure_diastolic  predicted_risk  risk_probability  \n",
            "0                 67.676162               1          0.669645  \n",
            "1                 81.070482               0          0.452906  \n",
            "2                 85.199407               0          0.327507  \n",
            "3                 79.579816               1          0.677214  \n",
            "4                 73.109857               1          0.717186  \n",
            "\n",
            "Predicted Risk: 0 = Low Risk, 1 = High Risk\n"
          ]
        }
      ]
    }
  ]
}